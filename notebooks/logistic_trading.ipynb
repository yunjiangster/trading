{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOK2V14CcWgrTmKDHxmGW8B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunjiangster/trading/blob/main/notebooks/logistic_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZJSWko1u1Tq"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from pandas_datareader.data import DataReader\n",
        "# from pandas.io.data import DataReader\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.lda import LDA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "# from sklearn.qda import QDA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = pd.DataFrame({'a': [1,2,3]})"
      ],
      "metadata": {
        "id": "wMD_oH6lwwK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.index = ['2', '3', '4']"
      ],
      "metadata": {
        "id": "VcyzFZYOwv5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_ticker = '^GSPC'\n",
        "start_date, end_date = '2001-01-10', '2005-12-31'\n",
        "start, end = map(date_str_to_ts, [start_date, end_date])\n",
        "url = ('https://query1.finance.yahoo.com/v7/finance/download/' + \n",
        "           stock_ticker + '?period1=' + str(start) + '&period2=' + str(end) + \n",
        "           '&interval=1d&events=history')\n",
        "ts = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "OCXwCnzvw1No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, math, sys, re\n",
        "import requests\n",
        "header = requests.get('https://raw.githubusercontent.com/yunjiangster/trading/main/data/eth/header.csv').content.decode().split('\\n')[0].split(',')\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/yunjiangster/trading/main/data/eth/ETHUSDT-201708xx-20220921.csv', header=None)\n",
        "df.columns = header"
      ],
      "metadata": {
        "id": "ZJbHR2A6gxFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Adj Close'] = df['Close']"
      ],
      "metadata": {
        "id": "SYGUfhO1xOa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime as dt\n",
        "df['Date'] = df['Open time'].apply(lambda x: dt.fbromtimestamp(x / 1e3).strftime('%Y-%m-%d'))"
      ],
      "metadata": {
        "id": "Xukyak1nhIFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def date_str_to_ts(date_str):\n",
        "  if isinstance(date_str, (list, tuple)):\n",
        "    return (pd.to_datetime(date_str).astype(int) // 10**9).to_list()\n",
        "  return pd.to_datetime([date_str]).astype(int)[0] // 10**9"
      ],
      "metadata": {
        "id": "49mG31cdxNF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lagged_series(symbol, start_date, end_date, lags=5, ts=None):\n",
        "    \"\"\"This creates a pandas DataFrame that stores the percentage returns of the \n",
        "    adjusted closing value of a stock obtained from Yahoo Finance, along with \n",
        "    a number of lagged returns from the prior trading days (lags defaults to 5 days).\n",
        "    Trading volume, as well as the Direction from the previous day, are also included.\"\"\"\n",
        "\n",
        "    # Obtain stock information from Yahoo Finance\n",
        "    # ts = DataReader(symbol, \"yahoo\", start_date-datetime.timedelta(days=365), end_date)\n",
        "    stock_ticker = symbol\n",
        "    # start = pd.to_datetime(['2007-01-01']).astype(int)[0]//10**9 # convert to unix timestamp.\n",
        "    # end = pd.to_datetime(['2020-12-31']).astype(int)[0]//10**9 # convert to unix timestamp.\n",
        "    start = date_str_to_ts(start_date)\n",
        "    end = date_str_to_ts(end_date)\n",
        "    if ts is None:\n",
        "      url = ('https://query1.finance.yahoo.com/v7/finance/download/' + \n",
        "            stock_ticker + '?period1=' + str(start) + '&period2=' + str(end) + \n",
        "            '&interval=1d&events=history')\n",
        "      ts = pd.read_csv(url)\n",
        "    ts.index = ts.Date\n",
        "\n",
        "    # # Create the new lagged DataFrame\n",
        "    tslag = pd.DataFrame(index=ts.index)\n",
        "    tslag[\"Today\"] = ts[\"Adj Close\"]\n",
        "    tslag[\"Volume\"] = ts[\"Volume\"]\n",
        "\n",
        "    # Create the shifted lag series of prior trading period close values\n",
        "    for i in range(0,lags):\n",
        "        tslag[\"Lag%s\" % str(i+1)] = ts[\"Adj Close\"].shift(i+1)\n",
        "    # Create the returns DataFrame\n",
        "    tsret = pd.DataFrame(index=tslag.index)\n",
        "    tsret[\"Volume\"] = tslag[\"Volume\"]\n",
        "    tsret[\"Today\"] = tslag[\"Today\"].pct_change()*100.0\n",
        "\n",
        "    # If any of the values of percentage returns equal zero, set them to\n",
        "    # a small number (stops issues with QDA model in scikit-learn)\n",
        "    for i,x in enumerate(tsret[\"Today\"]):\n",
        "        if (abs(x) < 0.0001):\n",
        "            tsret[\"Today\"][i] = 0.0001\n",
        "\n",
        "    # Create the lagged percentage returns columns\n",
        "    for i in range(lags):\n",
        "        tsret[\"Lag%s\" % str(i+1)] = tslag[\"Lag%s\" % str(i+1)].pct_change()*100.0\n",
        "\n",
        "    # Create the \"Direction\" column (+1 or -1) indicating an up/down day\n",
        "    tsret[\"Direction\"] = np.sign(tsret[\"Today\"])\n",
        "    tsret = tsret[tsret.index >= start_date]\n",
        "\n",
        "    return tsret"
      ],
      "metadata": {
        "id": "7TwyUBdAu5of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_model(name, model, X_train, y_train, X_test, pred):\n",
        "    \"\"\"Fits a classification model (for our purposes this is LR, LDA and QDA)\n",
        "    using the training data, then makes a prediction and subsequent \"hit rate\"\n",
        "    for the test data.\"\"\"\n",
        "\n",
        "    # Fit and predict the model on the training, and then test, data\n",
        "    model.fit(X_train, y_train)\n",
        "    pred[name] = model.predict(X_test)\n",
        "\n",
        "    # Create a series with 1 being correct direction, 0 being wrong\n",
        "    # and then calculate the hit rate based on the actual direction\n",
        "    pred[\"%s_Correct\" % name] = (1.0+pred[name]*pred[\"Actual\"])/2.0\n",
        "    hit_rate = np.mean(pred[\"%s_Correct\" % name])\n",
        "    print(\"%s: %.3f\" % (name, hit_rate))"
      ],
      "metadata": {
        "id": "rd06_U6ZvUbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Create a lagged series of the S&P500 US stock market index\n",
        "    # snpret = create_lagged_series(\"^GSPC\", '2001-01-10', '2005-12-31', lags=5)\n",
        "\n",
        "    snpret = create_lagged_series(\"ETH\", '2017-08-17', '2022-09-21', lags=5, ts=df)\n",
        "    # Use the prior two days of returns as predictor values, with direction as the response\n",
        "    X = snpret[[\"Lag1\",\"Lag2\", 'Lag3', 'Lag4', 'Lag5']]\n",
        "    y = snpret[\"Direction\"]\n",
        "\n",
        "    # The test data is split into two parts: Before and after 1st Jan 2005.\n",
        "    start_test = '2022-01-01'\n",
        "    start_train = '2017-08-%d' % (17 + 5) # exclude NaN's. \n",
        "    # Create training and test sets\n",
        "    X_train = X[(X.index < start_test) & (X.index > start_train)]\n",
        "\n",
        "    X_test = X[X.index >= start_test]\n",
        "    y_train = y[(y.index < start_test) & (X.index > start_train)]\n",
        "    y_test = y[y.index >= start_test]\n",
        "\n",
        "    # Create prediction DataFrame\n",
        "    pred = pd.DataFrame(index=y_test.index)\n",
        "    pred[\"Actual\"] = y_test\n",
        "    \n",
        "    # Create and fit the three models    \n",
        "    print(\"Hit Rates:\")\n",
        "    models = [(\"LR\", LogisticRegression()), (\"LDA\", LDA()), (\"QDA\", QDA())]\n",
        "    for m in models:\n",
        "        fit_model(m[0], m[1], X_train, y_train, X_test, pred)"
      ],
      "metadata": {
        "id": "EgWw6AcQvWdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pWTOtK_N0Bsa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}